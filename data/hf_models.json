[
  {
    "name": "nomic-ai/nomic-embed-text-v1.5",
    "provider": "Nomic",
    "parameter_count": "137M",
    "parameters_raw": 137000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "F16",
    "context_length": 8192,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "nomic_bert",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "BAAI/bge-large-en-v1.5",
    "provider": "BAAI",
    "parameter_count": "335M",
    "parameters_raw": 335142400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 512,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "bert",
    "hf_downloads": 4887046,
    "hf_likes": 627
  },
  {
    "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "provider": "Community",
    "parameter_count": "1.1B",
    "parameters_raw": 1100048384,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1770914,
    "hf_likes": 1525
  },
  {
    "name": "meta-llama/Llama-3.2-1B",
    "provider": "Meta",
    "parameter_count": "1.2B",
    "parameters_raw": 1235814400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1853952,
    "hf_likes": 2293
  },
  {
    "name": "stabilityai/stablelm-2-1_6b-chat",
    "provider": "Stability AI",
    "parameter_count": "1.6B",
    "parameters_raw": 1644515328,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "stablelm",
    "hf_downloads": 403,
    "hf_likes": 34
  },
  {
    "name": "google/gemma-2-2b-it",
    "provider": "Google",
    "parameter_count": "2.6B",
    "parameters_raw": 2614341888,
    "min_ram_gb": 1.5,
    "recommended_ram_gb": 2.4,
    "min_vram_gb": 1.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 334622,
    "hf_likes": 1284
  },
  {
    "name": "meta-llama/Llama-3.2-3B",
    "provider": "Meta",
    "parameter_count": "3.2B",
    "parameters_raw": 3212749824,
    "min_ram_gb": 1.8,
    "recommended_ram_gb": 3.0,
    "min_vram_gb": 1.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 803855,
    "hf_likes": 697
  },
  {
    "name": "microsoft/phi-3-mini-4k-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3.5-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, long context",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "01-ai/Yi-6B-Chat",
    "provider": "01.ai",
    "parameter_count": "6.1B",
    "parameters_raw": 6061035520,
    "min_ram_gb": 3.4,
    "recommended_ram_gb": 5.6,
    "min_vram_gb": 3.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 12988,
    "hf_likes": 70
  },
  {
    "name": "meta-llama/CodeLlama-7b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "6.7B",
    "parameters_raw": 6738546688,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 3305,
    "hf_likes": 59
  },
  {
    "name": "microsoft/Orca-2-7b",
    "provider": "Microsoft",
    "parameter_count": "7.0B",
    "parameters_raw": 7016400896,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-7b",
    "provider": "BigCode",
    "parameter_count": "7.2B",
    "parameters_raw": 7173923840,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 16730,
    "hf_likes": 209
  },
  {
    "name": "tiiuae/falcon-7b-instruct",
    "provider": "TII",
    "parameter_count": "7.2B",
    "parameters_raw": 7217189760,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 42085,
    "hf_likes": 1030
  },
  {
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "provider": "HuggingFace",
    "parameter_count": "7.2B",
    "parameters_raw": 7241732096,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 74535,
    "hf_likes": 1833
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "provider": "Mistral AI",
    "parameter_count": "7.2B",
    "parameters_raw": 7248023552,
    "min_ram_gb": 4.1,
    "recommended_ram_gb": 6.8,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mistral",
    "hf_downloads": 1200708,
    "hf_likes": 2419
  },
  {
    "name": "Qwen/Qwen2.5-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 12751133,
    "hf_likes": 1072
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "provider": "DeepSeek",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 707158,
    "hf_likes": 787
  },
  {
    "name": "meta-llama/Llama-3.1-8B",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1205931,
    "hf_likes": 2062
  },
  {
    "name": "meta-llama/Llama-3.1-8B-Instruct",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 5713509,
    "hf_likes": 5456
  },
  {
    "name": "mistralai/Ministral-8B-Instruct-2410",
    "provider": "Mistral AI",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-8B",
    "provider": "Alibaba",
    "parameter_count": "8.2B",
    "parameters_raw": 8190735360,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.6,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 4685993,
    "hf_likes": 934
  },
  {
    "name": "google/gemma-2-9b-it",
    "provider": "Google",
    "parameter_count": "9.2B",
    "parameters_raw": 9241705984,
    "min_ram_gb": 5.2,
    "recommended_ram_gb": 8.6,
    "min_vram_gb": 4.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 136774,
    "hf_likes": 768
  },
  {
    "name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "provider": "Meta",
    "parameter_count": "10.7B",
    "parameters_raw": 10670220835,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 9.9,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "mllama",
    "hf_downloads": 170781,
    "hf_likes": 1563
  },
  {
    "name": "google/gemma-3-12b-it",
    "provider": "Google",
    "parameter_count": "12B",
    "parameters_raw": 12000000000,
    "min_ram_gb": 6.7,
    "recommended_ram_gb": 11.2,
    "min_vram_gb": 6.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Nemo-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "12.2B",
    "parameters_raw": 12247076864,
    "min_ram_gb": 6.8,
    "recommended_ram_gb": 11.4,
    "min_vram_gb": 6.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-13b",
    "provider": "Microsoft",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-13b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "13.0B",
    "parameters_raw": 13016028160,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 3852,
    "hf_likes": 27
  },
  {
    "name": "microsoft/phi-4",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Reasoning, STEM, code generation",
    "pipeline_tag": "text-generation",
    "architecture": "phi",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3-medium-14b-instruct",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Balanced performance and size",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-15b",
    "provider": "BigCode",
    "parameter_count": "15.7B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "provider": "DeepSeek",
    "parameter_count": "16B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v2",
    "is_moe": true,
    "num_experts": 64,
    "active_experts": 6,
    "active_parameters": 2400000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Small-24B-Instruct-2501",
    "provider": "Mistral AI",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-27b-it",
    "provider": "Google",
    "parameter_count": "27.2B",
    "parameters_raw": 27227128320,
    "min_ram_gb": 15.2,
    "recommended_ram_gb": 25.4,
    "min_vram_gb": 13.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 387056,
    "hf_likes": 559
  },
  {
    "name": "Qwen/Qwen2.5-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.5B",
    "parameters_raw": 32510000000,
    "min_ram_gb": 18.2,
    "recommended_ram_gb": 30.3,
    "min_vram_gb": 16.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-32B",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32762123264,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 1560791,
    "hf_likes": 654
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "provider": "DeepSeek",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1226387,
    "hf_likes": 1515
  },
  {
    "name": "meta-llama/CodeLlama-34b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "33.7B",
    "parameters_raw": 33743970304,
    "min_ram_gb": 18.9,
    "recommended_ram_gb": 31.4,
    "min_vram_gb": 17.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1067,
    "hf_likes": 18
  },
  {
    "name": "01-ai/Yi-34B-Chat",
    "provider": "01.ai",
    "parameter_count": "34.4B",
    "parameters_raw": 34388917248,
    "min_ram_gb": 19.2,
    "recommended_ram_gb": 32.0,
    "min_vram_gb": 17.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13208,
    "hf_likes": 357
  },
  {
    "name": "CohereForAI/c4ai-command-r-v01",
    "provider": "Cohere",
    "parameter_count": "35B",
    "parameters_raw": 35000000000,
    "min_ram_gb": 19.5,
    "recommended_ram_gb": 32.6,
    "min_vram_gb": 17.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "RAG, tool use, agents",
    "pipeline_tag": "text-generation",
    "architecture": "cohere",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "46.7B",
    "parameters_raw": 46702792704,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 542837,
    "hf_likes": 4639,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "provider": "NousResearch",
    "parameter_count": "46.7B",
    "parameters_raw": 46702809088,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mixtral",
    "hf_downloads": 8064,
    "hf_likes": 453,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "meta-llama/Llama-3.1-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 707708,
    "hf_likes": 888
  },
  {
    "name": "meta-llama/Llama-3.3-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-72B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "72.7B",
    "parameters_raw": 72706203648,
    "min_ram_gb": 40.6,
    "recommended_ram_gb": 67.7,
    "min_vram_gb": 37.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 336890,
    "hf_likes": 910
  },
  {
    "name": "meta-llama/Llama-3.1-405B-Instruct",
    "provider": "Meta",
    "parameter_count": "405.9B",
    "parameters_raw": 405853388800,
    "min_ram_gb": 226.8,
    "recommended_ram_gb": 378.0,
    "min_vram_gb": 207.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 147548,
    "hf_likes": 591
  },
  {
    "name": "deepseek-ai/DeepSeek-V3",
    "provider": "DeepSeek",
    "parameter_count": "685B",
    "parameters_raw": 685000000000,
    "min_ram_gb": 382.8,
    "recommended_ram_gb": 638.0,
    "min_vram_gb": 351.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  }
]